[application]
enable-perf-measurement=1
perf-measurement-interval-sec=5

[tiled-display]
enable=0
rows=1
columns=1
width=1280
height=720
gpu-id=0
nvbuf-memory-type=0

[source0]
enable=1
type=4
uri=rtsp://192.168.1.193:25544/live/test
#rtsp://192.168.1.193:25544/live/test
num-sources=1
gpu-id=0
cudadec-memtype=0
rtsp-reconnect-interval-sec=30
rtsp-reconnect-attempts=-1
latency=200
select-rtp-protocol=4

[pre-process]
enable=0
config-file=config_preprocess.txt

[sink0]
enable=1
type=4
sync=1
source-id=0
gpu-id=0
nvbuf-memory-type=0
codec=1
bitrate=4000000
iframeinterval=15
rtsp-port=8555
udp-port=5400
width=1920
height=1080
profile=4
udp-buffer-size=100000

# redis
[sink1]
enable=0
#Type - 1=FakeSink 2=EglSink 3=File 4=UDPSink 5=nvdrmvideosink 6=MsgConvBroker
type=6
msg-conv-config=dstest5_msgconv_sample_config.txt
#(0): PAYLOAD_DEEPSTREAM - Deepstream schema payload
#(1): PAYLOAD_DEEPSTREAM_MINIMAL - Deepstream schema payload minimal
#(256): PAYLOAD_RESERVED - Reserved type
#(257): PAYLOAD_CUSTOM   - Custom schema payload
msg-conv-payload-type=0
msg-broker-proto-lib=/opt/nvidia/deepstream/deepstream/lib/libnvds_redis_proto.so
#Provide your msg-broker-conn-str here
msg-broker-conn-str=127.0.0.1;6379;dddd
topic=dddd
#Optional:
#msg-broker-config=../../deepstream-test4/cfg_kafka.txt

# 自定义的udp组播
[sink2]
enable=1
#Type - 1=FakeSink 2=EglSink 3=File 4=UDPSink 5=nvdrmvideosink 6=MsgConvBroker 7=MyNetwork
type=7

[message-converter]
enable=0
msg-conv-config=dstest5_msgconv_sample_config.txt
#(0): PAYLOAD_DEEPSTREAM - Deepstream schema payload
#(1): PAYLOAD_DEEPSTREAM_MINIMAL - Deepstream schema payload minimal
#(256): PAYLOAD_RESERVED - Reserved type
#(257): PAYLOAD_CUSTOM   - Custom schema payload
msg-conv-payload-type=0
# Name of library having custom implementation.
#msg-conv-msg2p-lib=<val>
# Id of component in case only selected message to parse.
#msg-conv-comp-id=<val>W

[osd]
enable=1
gpu-id=0
border-width=5
text-size=15
text-color=1;1;1;1;
text-bg-color=0.3;0.3;0.3;1
font=Serif
show-clock=1
clock-x-offset=100
clock-y-offset=80
clock-text-size=12
clock-color=1;0;0;0
nvbuf-memory-type=0

[streammux]
gpu-id=0
live-source=1
batch-size=1
batched-push-timeout=40000
width=1920
height=1080
enable-padding=0
nvbuf-memory-type=0

# 直接推理
[primary-gie]
enable=1
gpu-id=0
gie-unique-id=1
#(0): nvinfer - Default inference plugin based on Tensorrt
#(1): nvinferserver - inference plugin based on Tensorrt-Inference-Server
plugin-type=0
nvbuf-memory-type=0
input-tensor-meta=0
# input-tensor-meta=1
config-file=config_infer_primary_yoloV11.txt

# 通过triton调用模型
# [primary-gie]
# enable=1
# gpu-id=0
# #(0): nvinfer - Default inference plugin based on Tensorrt
# #(1): nvinferserver - inference plugin based on Tensorrt-Inference-Server
# plugin-type=1
# batch-size=1
# interval=0
# gie-unique-id=1
# nvbuf-memory-type=0
# config-file=config_infer_triton_yolov11.txt

[secondary-pre-process0]
enable=0
operate-on-gie-id=1
config-file=config_preprocess_sgie.txt

#[secondary-gie0]
#enable=1
##(0): nvinfer; (1): nvinferserver
#plugin-type=1
#input-tensor-meta=1
## nvinferserserver's gpu-id can only set from its own config-file
#gpu-id=0
#batch-size=8
#gie-unique-id=4
#operate-on-gie-id=1
#operate-on-class-ids=0;1;2
#config-file=config_infer_secondary_plan_engine_preprocess.txt

# 通过triton调用模型
# [secondary-gie0]
# enable=0
# #(0): nvinfer; (1): nvinferserver
# plugin-type=1
# gpu-id=0
# batch-size=1
# gie-unique-id=4
# operate-on-gie-id=1
# operate-on-class-ids=0;
# config-file=config_infer_secondary_plan_engine.txt

# 直接调用模型
[secondary-gie0]
enable=0
gpu-id=0
batch-size=1
gie-unique-id=4
operate-on-gie-id=1
# operate-on-class-ids=0;1
config-file=config_infer_secondary_classify.txt

# [tracker]
# enable=1
# # For NvDCF and NvDeepSORT tracker, tracker-width and tracker-height must be a multiple of 32, respectively
# tracker-width=960
# tracker-height=544
# ll-lib-file=/opt/nvidia/deepstream/deepstream/lib/libnvds_nvmultiobjecttracker.so
# # ll-config-file required to set different tracker types
# # ll-config-file=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_IOU.yml
# # ll-config-file=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_NvSORT.yml
# ll-config-file=config_tracker_NvDCF_perf.yml
# # config_tracker_NvDCF_perf.yml
# # ll-config-file=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_NvDCF_accuracy.yml
# # ll-config-file=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_NvDeepSORT.yml
# gpu-id=0
# display-tracking-id=1

# 自定义的单目标跟踪
[tracker]
enable=0
# For NvDCF and NvDeepSORT tracker, tracker-width and tracker-height must be a multiple of 32, respectively
tracker-width=1920
tracker-height=1080
ll-lib-file=/workspaces/Deepstream_template/deepstream/src/Mixformer_plugin/lib/libmixformer.so
gpu-id=0
display-tracking-id=1

[tests]
file-loop=0
