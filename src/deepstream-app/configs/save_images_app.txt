[application]
enable-perf-measurement=1
perf-measurement-interval-sec=5

[tiled-display]
enable=1
rows=1
columns=2
width=1600
height=600
gpu-id=0
nvbuf-memory-type=0

[source0]
enable=1
type=4
uri=rtsp://192.168.1.80/live/test
#rtsp://192.168.1.193:25544/live/test
#rtsp://192.168.1.193:25544/live/test
#rtsp://admin:Abc.12345@192.168.1.64/ch1/stream0
num-sources=1
gpu-id=0
cudadec-memtype=0
rtsp-reconnect-interval-sec=3
rtsp-reconnect-attempts=-1
latency=200
select-rtp-protocol=4

[source1]
enable=1
type=4
uri=rtsp://192.168.1.80/live/rgb
#rtsp://192.168.1.193:25544/live/test
#rtsp://192.168.1.193:25544/live/test
#rtsp://admin:Abc.12345@192.168.1.64/ch1/stream0
num-sources=1
gpu-id=0
cudadec-memtype=0
rtsp-reconnect-interval-sec=3
rtsp-reconnect-attempts=-1
latency=200
select-rtp-protocol=4

[sink0]
enable=1
type=4
sync=1
source-id=0
gpu-id=0
nvbuf-memory-type=0
codec=1
bitrate=2000000
iframeinterval=15
rtsp-port=8555
udp-port=5400
width=1280
height=720
profile=4
udp-buffer-size=100000

[osd]
enable=1
gpu-id=0
border-width=5
text-size=15
text-color=1;1;1;1;
text-bg-color=0.3;0.3;0.3;1
font=Serif
show-clock=1
clock-x-offset=100
clock-y-offset=80
clock-text-size=12
clock-color=1;0;0;0
nvbuf-memory-type=0

[streammux]
gpu-id=0
live-source=1
batch-size=2
batched-push-timeout=40000
width=1280
height=720
nvbuf-memory-type=0
attach-sys-ts-as-ntp=0
enable-padding=1
sync-inputs=1

# 直接推理
[primary-gie]
enable=1
gpu-id=0
gie-unique-id=1
#(0): nvinfer - Default inference plugin based on Tensorrt
#(1): nvinferserver - inference plugin based on Tensorrt-Inference-Server
plugin-type=0
nvbuf-memory-type=0
input-tensor-meta=0
# input-tensor-meta=1
config-file=config_infer_primary_yoloV11.txt