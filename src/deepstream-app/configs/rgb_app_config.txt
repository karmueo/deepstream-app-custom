[application]
enable-perf-measurement=1
perf-measurement-interval-sec=5
#enable-jpeg-save=1

[source0]
enable=1
type=4
uri=rtsp://192.168.1.80/live/rgb
#rtsp://192.168.1.80/live/rgb
#rtsp://admin:12345yyz@192.168.1.21:554/h264/ch1/main/av_stream
#rtsp://192.168.2.9:8554/ds-test
#rtsp://192.168.1.110/live/rgb
#rtsp://192.168.1.193:25544/live/test
#rtsp://192.168.1.193:25544/live/test
#rtsp://admin:Abc.12345@192.168.1.64/ch1/stream0
num-sources=1
gpu-id=0
cudadec-memtype=0
rtsp-reconnect-interval-sec=3
rtsp-reconnect-attempts=-1
latency=300
select-rtp-protocol=4
smart-record=1
smart-rec-dir-path=/workspace/deepstream-app-custom/smart_rec_rgb
smart-rec-default-duration=180
#smart-rec-duration=20
#smart-rec-start-time=5

[sink0]
enable=1
type=4
sync=1
source-id=0
gpu-id=0
nvbuf-memory-type=0
codec=1
bitrate=4000000
#bitrate=1800000
iframeinterval=15
rtsp-port=8556
udp-port=5401
width=1920
height=1080
profile=4
udp-buffer-size=524288

## redis
#[sink1]
#enable=0
##Type - 1=FakeSink 2=EglSink 3=File 4=UDPSink 5=nvdrmvideosink 6=MsgConvBroker
#type=6
#msg-conv-config=dstest5_msgconv_sample_config.txt
##(0): PAYLOAD_DEEPSTREAM - Deepstream schema payload
##(1): PAYLOAD_DEEPSTREAM_MINIMAL - Deepstream schema payload minimal
##(256): PAYLOAD_RESERVED - Reserved type
##(257): PAYLOAD_CUSTOM   - Custom schema payload
#msg-conv-payload-type=0
#msg-broker-proto-lib=/opt/nvidia/deepstream/deepstream/lib/libnvds_redis_proto.so
##Provide your msg-broker-conn-str here
#msg-broker-conn-str=127.0.0.1;6379;dddd
#topic=dddd
##Optional:
##msg-broker-config=../../deepstream-test4/cfg_kafka.txt

# 自定义的udp组播
[sink2]
enable=1
#Type - 1=FakeSink 2=EglSink 3=File 4=UDPSink 5=nvdrmvideosink 6=MsgConvBroker 7=MyNetwork
type=7
ip=239.255.10.10
multicast-port=6000
# multicast-ttl=32

[message-converter]
enable=0
msg-conv-config=dstest5_msgconv_sample_config.txt
#(0): PAYLOAD_DEEPSTREAM - Deepstream schema payload
#(1): PAYLOAD_DEEPSTREAM_MINIMAL - Deepstream schema payload minimal
#(256): PAYLOAD_RESERVED - Reserved type
#(257): PAYLOAD_CUSTOM   - Custom schema payload
msg-conv-payload-type=0
# Name of library having custom implementation.
#msg-conv-msg2p-lib=<val>
# Id of component in case only selected message to parse.
#msg-conv-comp-id=<val>W

[osd]
enable=1
gpu-id=0
border-width=2
text-size=20
text-color=1;1;1;1;
text-bg-color=0.3;0.3;0.3;1
font=Serif
show-clock=1
clock-x-offset=1700
clock-y-offset=15
clock-text-size=12
clock-color=1;0;0;0
nvbuf-memory-type=0

[streammux]
gpu-id=0
live-source=1
batch-size=1
batched-push-timeout=40000
width=1920
height=1080
enable-padding=1
nvbuf-memory-type=0
attach-sys-ts-as-ntp=0

[pre-process]
enable=1
config-file=config_preprocess_rgb_primary.txt

# 直接推理
[primary-gie]
enable=1
gpu-id=0
gie-unique-id=1
#(0): nvinfer - Default inference plugin based on Tensorrt
#(1): nvinferserver - inference plugin based on Tensorrt-Inference-Server
plugin-type=0
nvbuf-memory-type=0
input-tensor-meta=1
# input-tensor-meta=1
config-file=config_infer_primary_yoloV11_rgb.txt


# [tracker]
# enable=1
# # For NvDCF and NvDeepSORT tracker, tracker-width and tracker-height must be a multiple of 32, respectively
# tracker-width=960
# tracker-height=480
# ll-lib-file=/opt/nvidia/deepstream/deepstream/lib/libnvds_nvmultiobjecttracker.so
# # ll-config-file required to set different tracker types
# # ll-config-file=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_IOU.yml
# # ll-config-file=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_NvSORT.yml
# ll-config-file=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_NvDCF_perf.yml
# # config_tracker_NvDCF_perf.yml
# # ll-config-file=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_NvDCF_accuracy.yml
# # ll-config-file=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_NvDeepSORT.yml
# gpu-id=0
# display-tracking-id=1

# 自定义的单目标跟踪
[tracker]
enable=1
# For NvDCF and NvDeepSORT tracker, tracker-width and tracker-height must be a multiple of 32, respectively
tracker-width=1920
tracker-height=1080
ll-lib-file=/opt/nvidia/deepstream/deepstream/lib/libsot.so
ll-config-file=config_sot.yml
gpu-id=0
display-tracking-id=0

# [secondary-pre-process0]
# enable=0
# operate-on-gie-id=1
# config-file=config_preprocess_rgb_sgie.txt

[secondary-gie0]
enable=0
#(0): nvinfer; (1): nvinferserver
plugin-type=0
# Use preprocessed input tensors attached as metadata by nvdspreprocess plugin instead of preprocessing inside the nvinfer.
input-tensor-meta=0
# nvinferserserver's gpu-id can only set from its own config-file
gie-unique-id=4
operate-on-gie-id=1
operate-on-class-ids=0;1;2
config-file=config_infer_secondary_rgb_classify.txt

[videorecognition]
enable=0
unique-id=15
gpu-id=0
nvbuf-memory-type=3
#processing-width=32
#processing-height=32
processing-width=224
processing-height=224
model-clip-length=8
# keep-aspect-ratio=1
num-clips=4
# model-type: 0=multi-frame image classification (默认), 1=video recognition
model-type=1
#trt-engine-file=/workspace/deepstream-app-custom/src/deepstream-app/models/yolov11m_classify_rgb_b4_v2_fp16.engine
trt-engine-file=/workspace/deepstream-app-custom/src/gst-videorecognition/models/uniformerv2_softmax_rgb_fp16.engine

# Configure this group to enable cloud message consumer.
[message-consumer]
enable=1
proto-lib=/opt/nvidia/deepstream/deepstream/lib/libnvds_mqtt_proto.so
conn-str=127.0.0.1;1883
# config-file=cfg_mqtt.txt
subscribe-topic-list=command;test2;test3
# Use this option if message has sensor name as id instead of index (0,1,2 etc.).
#sensor-list-file=dstest5_msgconv_sample_config.txt

[tests]
file-loop=0
